{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "2021_fall_dsga1001_proj02_NETID.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wn1wahGPZzlD"
      },
      "source": [
        "### NYU CDS\n",
        "\n",
        "### Fall 2021\n",
        "\n",
        "### Introduction to Data Science\n",
        "\n",
        "### Project 2\n",
        "\n",
        "### student netid: qy692\n",
        "\n",
        "### deadline: Dec 06, 2021, 11:59pm"
      ],
      "id": "wn1wahGPZzlD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOSjwsREZzlJ"
      },
      "source": [
        "---\n",
        "# Data analysis Project 2\n",
        "### Correlation and Regression of Movie Ratings Data\n",
        "---"
      ],
      "id": "FOSjwsREZzlJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfacEui5ZzlK"
      },
      "source": [
        "### Dataset description\n",
        "\n",
        "This dataset features ratings data of 400 movies from 1097 research participants. \n",
        "\n",
        "* 1st row: Headers (Movie titles/questions) â€“ note that the indexing in this list is from 1\n",
        "* Row 2-1098: Responses from individual participants\n",
        "* Columns 1-400: These columns contain the ratings for the 400 movies (0 to 4, and missing)\n",
        "* Columns 401-421: These columns contain self-assessments on sensation seeking behaviors (1-5)\n",
        "* Columns 422-464: These columns contain responses to personality questions (1-5)\n",
        "* Columns 465-474: These columns contain self-reported movie experience ratings (1-5)\n",
        "* Column 475: Gender identity (1 = female, 2 = male, 3 = self-described)\n",
        "* Column 476: Only child (1 = yes, 0 = no, -1 = no response)\n",
        "* Column 477: Movies are best enjoyed alone (1 = yes, 0 = no, -1 = no response)\n",
        "\n",
        "Note that we did most of the data munging for you already (e.g. Python interprets commas in a csv file as separators, so we removed all commas from movie titles), but you still need to handle missing data."
      ],
      "id": "nfacEui5ZzlK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYbthxOcZzlL"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "### Q1:\n",
        "\n",
        "\n",
        "**Note:** For all missing values in the data, use the average of the corresponding column so to fill in the missing data. \n",
        "\n",
        "\n",
        "\n",
        "In this problem, under **the most correlated**, we consider the largest correlation in the absolute value.\n",
        "\n",
        "\n",
        "1.1. For every user in the given data, find its most correlated user. \n",
        "\n",
        "1.2. What is the pair of the most correlated users in the data? \n",
        "\n",
        "1.3. What is the value of this highest correlation?\n",
        "\n",
        "1.4. For users 0, 1, 2, \\dots, 9, print their most correlated users. \n",
        "\n"
      ],
      "id": "mYbthxOcZzlL"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vc-0vAPrZ3UL",
        "outputId": "82e9f06b-ad71-4261-ec4b-a168d7064f98"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "movieReplicationSet = pd.read_csv('/content/gdrive/My Drive/Introduction to data science-Project 2/movieReplicationSet.csv')"
      ],
      "id": "vc-0vAPrZ3UL",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljJzVbphahhx"
      },
      "source": [
        "data = movieReplicationSet.to_numpy()"
      ],
      "id": "ljJzVbphahhx",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dk-RRjXgc872"
      },
      "source": [
        "#Handling missing data: replace missing data with average of the corresponding column \n",
        "for i in range(477):\n",
        "    for j in range(1097):\n",
        "        if np.isnan(data[j][i]):\n",
        "            data[j][i] = np.nanmean(data[:,i])"
      ],
      "id": "Dk-RRjXgc872",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh7gSFLJdWQm"
      },
      "source": [
        "#For every user, calculate Pearson Coefficient with other users\n",
        "coefficients = np.zeros((1097,1097))\n",
        "for i in range(1097):\n",
        "    for j in range(1097):\n",
        "        coefficients[i][j] = abs(scipy.stats.pearsonr(data[i,:],data[j,:])[0])#correlation in the absolute value"
      ],
      "id": "hh7gSFLJdWQm",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6Fk4tw3darh"
      },
      "source": [
        "filtered_coefficients = []#filter out self-coefficients\n",
        "for i in range(1097):\n",
        "    temp = []\n",
        "    for j in range(1097):\n",
        "        if i!=j:\n",
        "            temp.append(coefficients[i][j])\n",
        "    filtered_coefficients.append(temp)\n",
        "filtered_coefficients = np.array(filtered_coefficients)"
      ],
      "id": "I6Fk4tw3darh",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P9KVTh3ddh6"
      },
      "source": [
        "#Question 1.1\n",
        "#Find most correlated users of each user\n",
        "most_correlated_users = []\n",
        "for i in range(1097):\n",
        "    most_correlated_users_i= []\n",
        "    for j in range(1097):\n",
        "        if i != j and coefficients[i][j] == np.max(filtered_coefficients[i,:]):\n",
        "            most_correlated_users_i.append([i,j])\n",
        "    most_correlated_users.append(most_correlated_users_i)\n",
        "most_correlated_users = np.array(most_correlated_users)"
      ],
      "id": "6P9KVTh3ddh6",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rmjH0JkdgnR",
        "outputId": "b0523135-c7e2-4bb6-b97b-535c42fa9ef4"
      },
      "source": [
        "#output of Question 1.1\n",
        "most_correlated_users#First number represent user, second number represents the index of its most correlated user"
      ],
      "id": "5rmjH0JkdgnR",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[   0,  583]],\n",
              "\n",
              "       [[   1,  831]],\n",
              "\n",
              "       [[   2,  896]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[1094,  896]],\n",
              "\n",
              "       [[1095,  392]],\n",
              "\n",
              "       [[1096,  559]]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3F-pM-d1dj2z"
      },
      "source": [
        "#Question 1.2\n",
        "#Find the most correlated users pair\n",
        "coe = []\n",
        "for i in range(1097):\n",
        "    index1, index2 = most_correlated_users[i][0][0], most_correlated_users[i][0][1]\n",
        "    coe.append(coefficients[index1][index2])"
      ],
      "id": "3F-pM-d1dj2z",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vegkDU9idmuc"
      },
      "source": [
        "most_correlated_pair = []\n",
        "for i in range(1097):\n",
        "    for j in range(1097):\n",
        "        if i!=j and coefficients[i][j] == max(coe):\n",
        "            most_correlated_pair.append([i,j])"
      ],
      "id": "vegkDU9idmuc",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6UwLUE8dpDb",
        "outputId": "ea702eb2-0877-41c1-f6ad-00f360c1a43d"
      },
      "source": [
        "#Output of Question 1.2\n",
        "most_correlated_pair#The most correlated pair of users is (831,896)"
      ],
      "id": "F6UwLUE8dpDb",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[831, 896], [896, 831]]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPJpmx4ndpzj",
        "outputId": "e03775e5-e8a9-4f45-deb6-62f792f96bb9"
      },
      "source": [
        "#Output of Question 1.3\n",
        "print(\"The coefficient of most correlated pair of users is: \",coefficients[831][896])"
      ],
      "id": "zPJpmx4ndpzj",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The coefficient of most correlated pair of users is:  0.9995424261495214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLyD7dJYdtFh",
        "outputId": "0c9cc790-57a8-4787-aac9-44cb266333f7"
      },
      "source": [
        "#Question 1.4\n",
        "#Print the most correlated user of user 0,1,2...9\n",
        "for i in range(10):\n",
        "    print(most_correlated_users[i][0])#second number represents the most correlated user of user i(i=0,1,2...9)"
      ],
      "id": "HLyD7dJYdtFh",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  0 583]\n",
            "[  1 831]\n",
            "[  2 896]\n",
            "[  3 364]\n",
            "[  4 896]\n",
            "[ 5 99]\n",
            "[  6 239]\n",
            "[  7 896]\n",
            "[  8 896]\n",
            "[   9 1004]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6XLF5h8eVp7"
      },
      "source": [
        "#Split the data into training and testing data\n",
        "training_data = data[:877,:]\n",
        "testing_data = data[878:,:]"
      ],
      "id": "x6XLF5h8eVp7",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOocrX2WZzlM"
      },
      "source": [
        "### Q2:\n",
        "\n",
        "We want to find a model between the ratings and the personal part of the data. To do so, consider:\n",
        "\n",
        "\n",
        "**Part 1**: the ratings of all users over columns 1-400: \n",
        "\n",
        "-- Columns 1-400: These columns contain the ratings for the 400 movies (0 to 4, and missing);\n",
        "\n",
        "call this part `df_rate`\n",
        "\n",
        "\n",
        "and \n",
        "\n",
        "\n",
        "**Part 2**:  the part of the data which includes all users over columns 401-474\n",
        "\n",
        "-- Columns 401-421: These columns contain self-assessments on sensation seeking behaviors (1-5)\n",
        "\n",
        "-- Columns 422-464: These columns contain responses to personality questions (1-5)\n",
        "\n",
        "-- Columns 465-474: These columns contain self-reported movie experience ratings (1-5)\n",
        "\n",
        "call this part `df_pers`.\n",
        "\n",
        "---\n",
        "\n",
        "Our main task is to model: \n",
        "\n",
        "\n",
        "`df_pers = function(df_rate)`\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Note:** Split the original data into training and testing as the ratio 0.80: 0.20. \n",
        "\n",
        "\n",
        "2.1. Model `df_pers = function(df_rate)` by using the linear regression. \n",
        "\n",
        "What are the errors on: (i) the training part; (ii) the testing part?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "2.2. Model `df_pers = function(df_rate)` by using the ridge regression with hyperparamter values alpha from [0.0, 1e-8, 1e-5, 0.1, 1, 10]. \n",
        "\n",
        "For every of the previous values for alpha, what are the errors on: (i) the training part; (ii) the testing part?\n",
        "\n",
        "What is a best choice for alpha?\n",
        "\n",
        "\n",
        "\n",
        "2.3. Model `df_pers = function(df_rate)` by using the lasso regression with hyperparamter values alpha from [1e-3, 1e-2, 1e-1, 1]. \n",
        "\n",
        "For every of the previous values for alpha, what are the errors on: (i) the training part; (ii) the testing part?\n",
        "\n",
        "What is a best choice for alpha?\n",
        "\n",
        "\n",
        "**Note**: Ignore any `convergence warning` in case you may obtain in the Lasso regression.\n",
        "\n",
        "\n"
      ],
      "id": "iOocrX2WZzlM"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjuEo3ughDvp"
      },
      "source": [
        "# df_train = pd.DataFrame(training_data,columns=row_1)#Training data\n",
        "# df_test = pd.DataFrame(testing_data,columns=row_1)#Testing data"
      ],
      "id": "fjuEo3ughDvp",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gw7IF80Nv821"
      },
      "source": [
        "df_rate_train = training_data[:,:400]#traing and testing data of df_rate\n",
        "df_rate_test = testing_data[:,:400]"
      ],
      "id": "gw7IF80Nv821",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86pauLpEwOyS"
      },
      "source": [
        "df_pers_train = training_data[:,400:474]#traing and testing data of df_pers\n",
        "df_pers_test = testing_data[:,400:474]"
      ],
      "id": "86pauLpEwOyS",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8UbOqlrvv8f",
        "outputId": "2f1a3f2b-f125-463e-8479-6f9a32f89cf2"
      },
      "source": [
        "#Question 2.1(1) multivariate regression of training data\n",
        "from sklearn import linear_model\n",
        "reg_train = linear_model.LinearRegression()#Do linear regression to training data\n",
        "x0 = df_rate_train\n",
        "y0 = df_pers_train\n",
        "reg_train.fit(x0,y0)"
      ],
      "id": "X8UbOqlrvv8f",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb230Kw5yAxh"
      },
      "source": [
        "#return coefficients and intercepts of training data\n",
        "coe_train = reg_train.coef_#array of coefficients\n",
        "inte_train = reg_train.intercept_#array of intercepts"
      ],
      "id": "xb230Kw5yAxh",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEabsF0Lf_1P"
      },
      "source": [
        "#predict y according to the coefs and intercepts\n",
        "y_predict_train = np.zeros((74,877))\n",
        "for i in range(74):\n",
        "  for j in range(877):\n",
        "    y_predict_train[i][j] = inte_train[i] + np.dot(coe_train[i,:],df_rate_train[j,:])"
      ],
      "id": "hEabsF0Lf_1P",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gxaTm79gAjC",
        "outputId": "d18a6a1e-7458-47ba-e6c8-b208a0ea23aa"
      },
      "source": [
        "#Calculate mean squared error of training data\n",
        "from sklearn.metrics import mean_squared_error\n",
        "y_true_train = df_pers_train\n",
        "y_predict_train = y_predict_train.T\n",
        "mean_squared_error(y_true_train, y_predict_train)"
      ],
      "id": "5gxaTm79gAjC",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6266333614264473"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwX_eo8srv4N"
      },
      "source": [
        "#Question 2.1(2)output the mse of testing data\n",
        "#predict y of testing data according to the coefs and intercepts from training data\n",
        "y_predict_test = np.zeros((74,219))\n",
        "for i in range(74):\n",
        "  for j in range(219):\n",
        "    y_predict_test[i][j] = inte_train[i] + np.dot(coe_train[i,:],df_rate_test[j,:])"
      ],
      "id": "CwX_eo8srv4N",
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjbBvBfDrv-a",
        "outputId": "e49072b3-46d4-479a-d343-9ddde601bb68"
      },
      "source": [
        "#Calculate mean squared error of testing data\n",
        "y_true_test = df_pers_test\n",
        "y_predict_test = y_predict_test.T\n",
        "mean_squared_error(y_true_test, y_predict_test)"
      ],
      "id": "fjbBvBfDrv-a",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.2724796291030422"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuYXdyFmtUG-"
      },
      "source": [
        "#Ridge Regression: min [sum(residuals_2)+lambada or hyperparameter or tuning coefficient*slope_2] ---L2 norm\n",
        "#when lambda = 0, it is a OLS, when lambda = infinite, the regression coefficients shrink to 0.\n",
        "#The assumption of Ridge Regression is that \"High coefficients are less likely than smaller ones\".\n",
        "#Lasso Regression(Least absolute shrinkage and selection operator): min[sum(residuals_2) + lamdba*|slope|]  ---L1 norm\n",
        "#Key features: slope could actually become 0, its assumption is \"Few meaningful/sparse coefficients\".\n",
        "#Both Ridge and Lasso Regression could deal with Multi-collinearity well."
      ],
      "id": "cuYXdyFmtUG-",
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVg3pyYq1SSm",
        "outputId": "88641673-9c5d-4d68-f4ca-e6b417cc7f72"
      },
      "source": [
        "#Question 2.2 \n",
        "#Applying Ridge Regression to Training data: alpha = 0.0\n",
        "#The same as OLS\n",
        "#Training Data\n",
        "from sklearn.linear_model import Ridge\n",
        "clf_train_1 = Ridge(alpha=0.0)\n",
        "clf_train_1.fit(x0, y0)\n",
        "\n",
        "clf_train_1_coe = clf_train_1.coef_#array of coefficients\n",
        "clf_train_1_inte = clf_train_1.intercept_#array of intercepts\n",
        "\n",
        "y_predict_train_1 = np.zeros((74,877))\n",
        "for i in range(74):\n",
        "  for j in range(877):\n",
        "     y_predict_train_1[i][j] = clf_train_1_inte[i] + np.dot(clf_train_1_coe[i,:],df_rate_train[j,:])\n",
        "\n",
        "y_true_train = df_pers_train\n",
        "y_predict_train_1 = y_predict_train_1.T\n",
        "mean_squared_error(y_true_train, y_predict_train_1)"
      ],
      "id": "yVg3pyYq1SSm",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6266333614264473"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPzNOdCN2Cen",
        "outputId": "3590b4cf-8f02-453d-a531-0e9389e8535f"
      },
      "source": [
        "#Testing Data: alpha = 0.0\n",
        "y_predict_test_1 = np.zeros((74,219))\n",
        "for i in range(74):\n",
        "  for j in range(219):\n",
        "    y_predict_test_1[i][j] = clf_train_1_inte[i] + np.dot(clf_train_1_coe[i,:],df_rate_test[j,:])\n",
        "\n",
        "y_true_test = df_pers_test\n",
        "y_predict_test_1 = y_predict_test_1.T\n",
        "mean_squared_error(y_true_test, y_predict_test_1)\n",
        "   "
      ],
      "id": "uPzNOdCN2Cen",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.2724796291030613"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmDpTHV8DMbV",
        "outputId": "4bddb411-0526-49e7-bd9e-568900c50201"
      },
      "source": [
        "#Applying Ridge Regression to Training data: alpha = 1e-8\n",
        "#Training Data\n",
        "from sklearn.linear_model import Ridge\n",
        "clf_train_2 = Ridge(alpha=1e-8)\n",
        "clf_train_2.fit(x0, y0)\n",
        "\n",
        "clf_train_2_coe = clf_train_2.coef_#array of coefficients\n",
        "clf_train_2_inte = clf_train_2.intercept_#array of intercepts\n",
        "\n",
        "y_predict_train_2 = np.zeros((74,877))\n",
        "for i in range(74):\n",
        "  for j in range(877):\n",
        "     y_predict_train_2[i][j] = clf_train_2_inte[i] + np.dot(clf_train_2_coe[i,:],df_rate_train[j,:])\n",
        "\n",
        "y_true_train = df_pers_train\n",
        "y_predict_train_2 = y_predict_train_2.T\n",
        "mean_squared_error(y_true_train, y_predict_train_2)"
      ],
      "id": "fmDpTHV8DMbV",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6266333614264473"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0zEgELAESTG",
        "outputId": "7c8e948a-d32d-45d3-cfcc-e1c5c4b43845"
      },
      "source": [
        "#Testing Data: alpha = 1e-8\n",
        "y_predict_test_2 = np.zeros((74,219))\n",
        "for i in range(74):\n",
        "  for j in range(219):\n",
        "    y_predict_test_2[i][j] = clf_train_2_inte[i] + np.dot(clf_train_2_coe[i,:],df_rate_test[j,:])\n",
        "\n",
        "y_true_test = df_pers_test\n",
        "y_predict_test_2 = y_predict_test_2.T\n",
        "mean_squared_error(y_true_test, y_predict_test_2)"
      ],
      "id": "N0zEgELAESTG",
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.2724796180411304"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4c2jWVaEaSI",
        "outputId": "77dc3f73-1b2a-406b-8b33-d5ce3eb86a75"
      },
      "source": [
        "#Applying Ridge Regression to Training data: alpha = 1e-5\n",
        "#Training Data\n",
        "from sklearn.linear_model import Ridge\n",
        "clf_train_3 = Ridge(alpha=1e-5)\n",
        "clf_train_3.fit(x0, y0)\n",
        "\n",
        "clf_train_3_coe = clf_train_3.coef_#array of coefficients\n",
        "clf_train_3_inte = clf_train_3.intercept_#array of intercepts\n",
        "\n",
        "y_predict_train_3 = np.zeros((74,877))\n",
        "for i in range(74):\n",
        "  for j in range(877):\n",
        "     y_predict_train_3[i][j] = clf_train_3_inte[i] + np.dot(clf_train_3_coe[i,:],df_rate_train[j,:])\n",
        "\n",
        "y_true_train = df_pers_train\n",
        "y_predict_train_3 = y_predict_train_3.T\n",
        "mean_squared_error(y_true_train, y_predict_train_3)"
      ],
      "id": "t4c2jWVaEaSI",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6266333614278393"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUZZbXP7Eu71",
        "outputId": "a96abc73-ffa3-4bfa-8414-8a10a3354dff"
      },
      "source": [
        "#Testing Data: alpha = 1e-5\n",
        "y_predict_test_3 = np.zeros((74,219))\n",
        "for i in range(74):\n",
        "  for j in range(219):\n",
        "    y_predict_test_3[i][j] = clf_train_3_inte[i] + np.dot(clf_train_3_coe[i,:],df_rate_test[j,:])\n",
        "\n",
        "y_true_test = df_pers_test\n",
        "y_predict_test_3 = y_predict_test_3.T\n",
        "mean_squared_error(y_true_test, y_predict_test_3)"
      ],
      "id": "cUZZbXP7Eu71",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.2724685672747684"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDBmBazoE7N-",
        "outputId": "9e282cba-4f35-4a05-e437-de4bd516ed36"
      },
      "source": [
        "#Applying Ridge Regression to Training data: alpha = 0.1\n",
        "#Training Data\n",
        "from sklearn.linear_model import Ridge\n",
        "clf_train_4 = Ridge(alpha=0.1)\n",
        "clf_train_4.fit(x0, y0)\n",
        "\n",
        "clf_train_4_coe = clf_train_4.coef_#array of coefficients\n",
        "clf_train_4_inte = clf_train_4.intercept_#array of intercepts\n",
        "\n",
        "y_predict_train_4 = np.zeros((74,877))\n",
        "for i in range(74):\n",
        "  for j in range(877):\n",
        "     y_predict_train_4[i][j] = clf_train_4_inte[i] + np.dot(clf_train_4_coe[i,:],df_rate_train[j,:])\n",
        "\n",
        "y_true_train = df_pers_train\n",
        "y_predict_train_4 = y_predict_train_4.T\n",
        "mean_squared_error(y_true_train, y_predict_train_4)"
      ],
      "id": "qDBmBazoE7N-",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6267540788299638"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_71ltmrdFSgu",
        "outputId": "8d18585b-0c0e-4b7f-821b-7bd55469c163"
      },
      "source": [
        "#Testing Data: alpha = 0.1\n",
        "y_predict_test_4 = np.zeros((74,219))\n",
        "for i in range(74):\n",
        "  for j in range(219):\n",
        "    y_predict_test_4[i][j] = clf_train_4_inte[i] + np.dot(clf_train_4_coe[i,:],df_rate_test[j,:])\n",
        "\n",
        "y_true_test = df_pers_test\n",
        "y_predict_test_4 = y_predict_test_4.T\n",
        "mean_squared_error(y_true_test, y_predict_test_4)"
      ],
      "id": "_71ltmrdFSgu",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.171372627566351"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5grd7r8FeA6",
        "outputId": "62fb3193-a3b2-446f-f310-329a483eb423"
      },
      "source": [
        "#Applying Ridge Regression to Training data: alpha = 1\n",
        "#Training Data\n",
        "from sklearn.linear_model import Ridge\n",
        "clf_train_5 = Ridge(alpha=1)\n",
        "clf_train_5.fit(x0, y0)\n",
        "\n",
        "clf_train_5_coe = clf_train_5.coef_#array of coefficients\n",
        "clf_train_5_inte = clf_train_5.intercept_#array of intercepts\n",
        "\n",
        "y_predict_train_5 = np.zeros((74,877))\n",
        "for i in range(74):\n",
        "  for j in range(877):\n",
        "     y_predict_train_5[i][j] = clf_train_5_inte[i] + np.dot(clf_train_5_coe[i,:],df_rate_train[j,:])\n",
        "\n",
        "y_true_train = df_pers_train\n",
        "y_predict_train_5 = y_predict_train_5.T\n",
        "mean_squared_error(y_true_train, y_predict_train_5)"
      ],
      "id": "u5grd7r8FeA6",
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6319762800786279"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kf7DotGhF2gr",
        "outputId": "18bf85ea-6156-44a3-8d38-0c90e521714d"
      },
      "source": [
        "#Testing Data: alpha = 1\n",
        "y_predict_test_5 = np.zeros((74,219))\n",
        "for i in range(74):\n",
        "  for j in range(219):\n",
        "    y_predict_test_5[i][j] = clf_train_5_inte[i] + np.dot(clf_train_5_coe[i,:],df_rate_test[j,:])\n",
        "\n",
        "y_true_test = df_pers_test\n",
        "y_predict_test_5 = y_predict_test_5.T\n",
        "mean_squared_error(y_true_test, y_predict_test_5)"
      ],
      "id": "kf7DotGhF2gr",
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.67145782928624"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpTsVEjAGBSe",
        "outputId": "e7fcc461-5cce-47b5-d6e6-a7bfeb302b1f"
      },
      "source": [
        "#Applying Ridge Regression to Training data: alpha = 10\n",
        "#Training Data\n",
        "from sklearn.linear_model import Ridge\n",
        "clf_train_6 = Ridge(alpha=10)\n",
        "clf_train_6.fit(x0, y0)\n",
        "\n",
        "clf_train_6_coe = clf_train_6.coef_#array of coefficients\n",
        "clf_train_6_inte = clf_train_6.intercept_#array of intercepts\n",
        "\n",
        "y_predict_train_6 = np.zeros((74,877))\n",
        "for i in range(74):\n",
        "  for j in range(877):\n",
        "     y_predict_train_6[i][j] = clf_train_6_inte[i] + np.dot(clf_train_6_coe[i,:],df_rate_train[j,:])\n",
        "\n",
        "y_true_train = df_pers_train\n",
        "y_predict_train_6 = y_predict_train_6.T\n",
        "mean_squared_error(y_true_train, y_predict_train_6)"
      ],
      "id": "VpTsVEjAGBSe",
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6843972902752351"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhBbFhX2GUDN",
        "outputId": "3f19e0d8-ebc5-40e2-b6fe-af8834590e22"
      },
      "source": [
        "#Testing Data: alpha = 10\n",
        "y_predict_test_6 = np.zeros((74,219))\n",
        "for i in range(74):\n",
        "  for j in range(219):\n",
        "    y_predict_test_6[i][j] = clf_train_6_inte[i] + np.dot(clf_train_6_coe[i,:],df_rate_test[j,:])\n",
        "\n",
        "y_true_test = df_pers_test\n",
        "y_predict_test_6 = y_predict_test_6.T\n",
        "mean_squared_error(y_true_test, y_predict_test_6)"
      ],
      "id": "HhBbFhX2GUDN",
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.8134992045163203"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j18OF8krHIqC"
      },
      "source": [
        "#Question 2.3\n",
        "from sklearn import linear_model\n",
        "\n",
        "def mse(alpha):\n",
        "  clf_train = linear_model.Lasso(alpha=alpha)#Lasso regression\n",
        "  clf_train.fit(x0, y0)\n",
        "\n",
        "  clf_train_coe = clf_train.coef_#array of coefficients\n",
        "  clf_train_inte = clf_train.intercept_#array of intercepts\n",
        "\n",
        "  y_predict_train = np.zeros((74,877))\n",
        "  for i in range(74):\n",
        "    for j in range(877):\n",
        "      y_predict_train[i][j] = clf_train_inte[i] + np.dot(clf_train_coe[i,:],df_rate_train[j,:])\n",
        "\n",
        "  y_true_train = df_pers_train\n",
        "  y_predict_train = y_predict_train.T\n",
        "  mse_training_data = mean_squared_error(y_true_train, y_predict_train)#MSE of Training data\n",
        "\n",
        "  y_predict_test = np.zeros((74,219))\n",
        "  for i in range(74):\n",
        "    for j in range(219):\n",
        "      y_predict_test[i][j] = clf_train_inte[i] + np.dot(clf_train_coe[i,:],df_rate_test[j,:])\n",
        "\n",
        "  y_true_test = df_pers_test\n",
        "  y_predict_test = y_predict_test.T\n",
        "  mse_testing_data = mean_squared_error(y_true_test, y_predict_test)#MSE of Testing data\n",
        "\n",
        "  return mse_training_data,mse_testing_data"
      ],
      "id": "j18OF8krHIqC",
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vp_vj2maIfSh",
        "outputId": "ca515e12-d07a-47cf-f791-ad3a7033d361"
      },
      "source": [
        "alphas = [1e-3,1e-2,1e-1,1]\n",
        "for i in range(4):\n",
        "  print(\"The MSE of training data and testing data are: \",str(mse(alphas[i])), \"respectively!\")"
      ],
      "id": "vp_vj2maIfSh",
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3378546771078845, tolerance: 0.1345218091234954\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3641935269693022, tolerance: 0.18976018372511416\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.11979160960385116, tolerance: 0.05534749402071681\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3946372903697011, tolerance: 0.15483057709652553\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.36776875303417, tolerance: 0.14383516161996163\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.15260907942410995, tolerance: 0.11017421159388889\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3524156904737765, tolerance: 0.15504401990770866\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1440064551281921, tolerance: 0.10939726488175908\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.22689539012412752, tolerance: 0.1254919066668495\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8657755119606918, tolerance: 0.19263017212319675\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2234222740593168, tolerance: 0.14632388578653485\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5135657584257842, tolerance: 0.0996109547837711\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4788969225819528, tolerance: 0.10200767110029131\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2122224913490527, tolerance: 0.10756482614279178\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6917634914266273, tolerance: 0.12921556381765845\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.14126823191509175, tolerance: 0.09860325536221415\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4468532340198408, tolerance: 0.12092074193747913\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0812065897746379, tolerance: 0.07144792933612056\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.31369544529468385, tolerance: 0.10417059491593883\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0935244333850278, tolerance: 0.06580959509832914\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.33143458749646015, tolerance: 0.09851747824136509\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.12455177740969248, tolerance: 0.11248359845025989\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.14421324618314202, tolerance: 0.05994816105555761\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2949754218124667, tolerance: 0.0940316930499924\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.286476816441791, tolerance: 0.09308067831280843\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.10604509462814349, tolerance: 0.07412362952277933\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.238603609781876, tolerance: 0.09265140519445782\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.27135784315078126, tolerance: 0.10650966924372166\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.287312153725793, tolerance: 0.13220417421150066\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.39077439390075597, tolerance: 0.10361907149475796\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.15712579932585413, tolerance: 0.11732660734450365\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.10704168763152211, tolerance: 0.09757249435692177\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1725178606030795, tolerance: 0.10922027115270913\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9896632834767161, tolerance: 0.11435276569870303\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.14027009318908767, tolerance: 0.0793839276439948\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.21428178199823833, tolerance: 0.11634483165243727\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9437301486290153, tolerance: 0.12455953118969822\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.259753259941931, tolerance: 0.09033439766830333\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.20179463171905354, tolerance: 0.06219817029465103\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.30867516669991346, tolerance: 0.07418436123887186\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.14106098138177003, tolerance: 0.09906760374918817\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3651326235219585, tolerance: 0.09124825430978101\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2147185686769717, tolerance: 0.09941947954778367\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.11763296242952492, tolerance: 0.10777787613318847\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.14342494650213666, tolerance: 0.08456899677860232\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.17944264292361822, tolerance: 0.1030025608042283\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.21417576459367638, tolerance: 0.06396122607415207\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.268709479131644, tolerance: 0.12824413803927973\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06866113020095099, tolerance: 0.059922476610941355\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1724085822829693, tolerance: 0.09994550415595017\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1370962050077651, tolerance: 0.11403264994550434\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6256209696247197, tolerance: 0.14506863241163043\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.353096440716854, tolerance: 0.1469426428752822\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5794970269075748, tolerance: 0.19490450269518875\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.24428773743704824, tolerance: 0.18134298839869384\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.26371213734626053, tolerance: 0.13381104718339998\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3136046351586401, tolerance: 0.13077253803806554\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3466615159009052, tolerance: 0.13347319585035783\n",
            "  positive)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The MSE of training data and testing data are:  (0.650790088732947, 2.228330416266972) respectively!\n",
            "The MSE of training data and testing data are:  (0.9112161458420326, 1.2926102652297646) respectively!\n",
            "The MSE of training data and testing data are:  (1.22435015141834, 1.1972310315042987) respectively!\n",
            "The MSE of training data and testing data are:  (1.2410883841984266, 1.2061919773142018) respectively!\n"
          ]
        }
      ]
    }
  ]
}